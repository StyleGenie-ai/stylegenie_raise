{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tags using NLP\n",
    "# filter them further using SPACY\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_tags(desc):\n",
    "    vectorizer = CountVectorizer(max_features=100, stop_words='english', ngram_range=(1, 2))\n",
    "    X = vectorizer.fit_transform([desc])\n",
    "    tags = vectorizer.get_feature_names_out()\n",
    "    keep = []\n",
    "    for term in tags:\n",
    "        doc = nlp(term.replace(\"_\", \" \"))\n",
    "        if all(token.pos_ in [\"NOUN\", \"ADJ\"] for token in doc):\n",
    "            keep.append(term.lower())\n",
    "    return list(set(keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize title + desc + image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load FashionCLIP model and processor from Hugging Face\n",
    "model_name = \"patrickjohncyh/fashion-clip\"\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "def vectorize(text, img):\n",
    "    # Load image\n",
    "    image = Image.open(img).convert(\"RGB\")\n",
    "\n",
    "    # 1. Get image embedding\n",
    "    img_inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    image_emb = model.get_image_features(**img_inputs)\n",
    "\n",
    "    # 2. Get text embedding\n",
    "    txt_inputs = processor(text=text, return_tensors=\"pt\", padding=True)\n",
    "    text_emb = model.get_text_features(**txt_inputs)\n",
    "\n",
    "    # 3. Normalize both embeddings\n",
    "    image_emb = torch.nn.functional.normalize(image_emb, p=2, dim=1)\n",
    "    text_emb = torch.nn.functional.normalize(text_emb, p=2, dim=1)\n",
    "\n",
    "    # 4. Combine and normalize again\n",
    "    combined_emb = (image_emb + text_emb) / 2\n",
    "    combined_emb = torch.nn.functional.normalize(combined_emb, p=2, dim=1)\n",
    "\n",
    "    return combined_emb[0].cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# men\n",
    "# load the json\n",
    "import json\n",
    "from pinecone import Pinecone, PodSpec\n",
    "\n",
    "f = open(\"men_db.json\", 'r')\n",
    "d = json.load(f)\n",
    "pc = Pinecone(api_key=\"\")\n",
    "index = pc.Index(\"menfit\")\n",
    "\n",
    "\n",
    "\n",
    "for i in d:\n",
    "    i['tags'] = get_tags(i['description'])\n",
    "    text = f\"{i['name']} . {i['description']}\"\n",
    "    img = i['path']\n",
    "\n",
    "    # get vector\n",
    "    vec = vectorize(text, img)\n",
    "\n",
    "    # save in pinecone\n",
    "    index.upsert([{\n",
    "        \"id\": i['id'],\n",
    "        \"values\": vec,\n",
    "        \"metadata\": i\n",
    "    }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# women\n",
    "# load the json\n",
    "import json\n",
    "from pinecone import Pinecone, PodSpec\n",
    "\n",
    "f = open(\"women_db.json\", 'r')\n",
    "d = json.load(f)\n",
    "pc = Pinecone(api_key=\"\")\n",
    "index = pc.Index(\"womanfit\")\n",
    "\n",
    "\n",
    "\n",
    "for i in d:\n",
    "    i['tags'] = get_tags(i['description'])\n",
    "    text = f\"{i['brand']} {i['name']} . {i['description']}\"\n",
    "    img = i['path']\n",
    "\n",
    "    # get vector\n",
    "    vec = vectorize(text, img)\n",
    "\n",
    "    # save in pinecone\n",
    "    index.upsert([{\n",
    "        \"id\": i['id'],\n",
    "        \"values\": vec,\n",
    "        \"metadata\": i\n",
    "    }])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
